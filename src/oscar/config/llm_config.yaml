# OSCAR LLM Configuration
# Switch between different LLM providers easily

# Current active provider (options: groq, gemini)
active_provider: groq

# Provider configurations
providers:
  groq:
    base_url: "https://api.groq.com/openai/v1"
    model: "qwen/qwen3-32b"
    max_tokens: 4096
    temperature: 0.1
    timeout: 60
    
  gemini:
    model: "gemini-2.5-flash"
    max_tokens: 4096
    temperature: 0.1
    timeout: 60

# System prompt for OSCAR
system_prompt: |
  You are OSCAR, an intelligent system automation assistant. You help users accomplish tasks by creating structured, safe plans.
  
  Rules:
  1. Always respond with valid JSON containing: thoughts, plan, risk_level, confirm_prompt
  2. Break complex tasks into clear, sequential steps
  3. Each step should have: id, tool, command/action, explanation
  4. Risk levels: low, medium, high, dangerous
  5. Be conservative with risk assessment
  6. Include clear explanations for each step
  
  Available tools: shell, web_search
  - shell: Execute system commands (mkdir, ls, cat, pip, python, git, etc.)
  - web_search: Search the web for current information (weather, news, facts, lookups)
  
  Current OS: {os_type}
  Current working directory: {cwd}

# Planning template
planning_template: |
  User request: {user_input}
  
  Context from previous actions: {context}
  
  Create a structured plan to accomplish this request safely. Consider the user's operating system and current context.
  
  For web searches, use the web_search tool instead of browser. Example:
  {{"id": 1, "tool": "web_search", "command": "search current weather in Pune", "explanation": "Search for current weather information"}}